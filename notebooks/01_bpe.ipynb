{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e806ada6",
   "metadata": {},
   "source": [
    "# Naive BPE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133107c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "# A humble corpus\n",
    "texts = [\n",
    "    \"low low low low low\",\n",
    "    \"lower lower widest widest widest\",\n",
    "    \"newest newest newest newest newest newest\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92303b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EOS> - a - b - c - d - e - f - g - h - i - j - k - l - m - n - o - p - q - r - s - t - u - v - w - x - y - z\n"
     ]
    }
   ],
   "source": [
    "vocabulary = [\"<EOS>\"] + [chr(k) for k in range(ord('a'), ord('z')+1)]\n",
    "\n",
    "print(\" - \".join(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16930b9",
   "metadata": {},
   "source": [
    "## Pretokenize texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5725cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gpt-2 pre-tokenization regex\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "def pre_tokenize(text: str) -> list[str]:\n",
    "    # A more complex pre-tokenizer\n",
    "    return re.findall(PAT, text)\n",
    "\n",
    "def whitespace_pretokenize(text: str) -> list[str]:\n",
    "    # Simple whitespace tokenizer\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac059a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola', ' mundo', '...']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tokenize(\"hola mundo...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73afd643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', '!', ' こんにちは', '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tokenize(\"hello! こんにちは!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d00c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(108, 111, 119): 5,\n",
       "             (108, 111, 119, 101, 114): 2,\n",
       "             (119, 105, 100, 101, 115, 116): 3,\n",
       "             (110, 101, 119, 101, 115, 116): 6})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "frequency_table: defaultdict[tuple[bytes], int] = defaultdict(int)\n",
    "\n",
    "for text in texts:\n",
    "    words = whitespace_pretokenize(text)\n",
    "\n",
    "    for word in words:\n",
    "        bytes_tuple = tuple(word.encode(\"utf-8\"))\n",
    "        frequency_table[bytes_tuple] += 1\n",
    "\n",
    "frequency_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed44727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'潬'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'low'[0:2].decode(\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c403089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token(byte_list=(196, 131, 111))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass, Field\n",
    "\n",
    "\n",
    "# Frozen makes them hashable\n",
    "@dataclass(frozen=True)\n",
    "class Token:\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # wtf is this shit.\n",
    "        # using to cast this\n",
    "        object.__setattr__(self, \"byte_list\", tuple(self.byte_list))\n",
    "\n",
    "    byte_list: tuple[bytes]\n",
    "\n",
    "ao_token = Token(chr(259).encode() + b\"o\") # strange way to write this\n",
    "\n",
    "ao_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73605a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao_token == Token(ao_token.byte_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "367d803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'\\xff', b'\\xff')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([255]), bytes(b'\\xff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c1471a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(byte_list=(0,)),\n",
       " Token(byte_list=(1,)),\n",
       " Token(byte_list=(2,)),\n",
       " Token(byte_list=(3,)),\n",
       " Token(byte_list=(4,)),\n",
       " Token(byte_list=(5,)),\n",
       " Token(byte_list=(6,)),\n",
       " Token(byte_list=(7,)),\n",
       " Token(byte_list=(8,)),\n",
       " Token(byte_list=(9,)),\n",
       " Token(byte_list=(10,)),\n",
       " Token(byte_list=(11,)),\n",
       " Token(byte_list=(12,)),\n",
       " Token(byte_list=(13,)),\n",
       " Token(byte_list=(14,)),\n",
       " Token(byte_list=(15,)),\n",
       " Token(byte_list=(16,)),\n",
       " Token(byte_list=(17,)),\n",
       " Token(byte_list=(18,)),\n",
       " Token(byte_list=(19,)),\n",
       " Token(byte_list=(20,)),\n",
       " Token(byte_list=(21,)),\n",
       " Token(byte_list=(22,)),\n",
       " Token(byte_list=(23,)),\n",
       " Token(byte_list=(24,)),\n",
       " Token(byte_list=(25,)),\n",
       " Token(byte_list=(26,)),\n",
       " Token(byte_list=(27,)),\n",
       " Token(byte_list=(28,)),\n",
       " Token(byte_list=(29,)),\n",
       " Token(byte_list=(30,)),\n",
       " Token(byte_list=(31,)),\n",
       " Token(byte_list=(32,)),\n",
       " Token(byte_list=(33,)),\n",
       " Token(byte_list=(34,)),\n",
       " Token(byte_list=(35,)),\n",
       " Token(byte_list=(36,)),\n",
       " Token(byte_list=(37,)),\n",
       " Token(byte_list=(38,)),\n",
       " Token(byte_list=(39,)),\n",
       " Token(byte_list=(40,)),\n",
       " Token(byte_list=(41,)),\n",
       " Token(byte_list=(42,)),\n",
       " Token(byte_list=(43,)),\n",
       " Token(byte_list=(44,)),\n",
       " Token(byte_list=(45,)),\n",
       " Token(byte_list=(46,)),\n",
       " Token(byte_list=(47,)),\n",
       " Token(byte_list=(48,)),\n",
       " Token(byte_list=(49,)),\n",
       " Token(byte_list=(50,)),\n",
       " Token(byte_list=(51,)),\n",
       " Token(byte_list=(52,)),\n",
       " Token(byte_list=(53,)),\n",
       " Token(byte_list=(54,)),\n",
       " Token(byte_list=(55,)),\n",
       " Token(byte_list=(56,)),\n",
       " Token(byte_list=(57,)),\n",
       " Token(byte_list=(58,)),\n",
       " Token(byte_list=(59,)),\n",
       " Token(byte_list=(60,)),\n",
       " Token(byte_list=(61,)),\n",
       " Token(byte_list=(62,)),\n",
       " Token(byte_list=(63,)),\n",
       " Token(byte_list=(64,)),\n",
       " Token(byte_list=(65,)),\n",
       " Token(byte_list=(66,)),\n",
       " Token(byte_list=(67,)),\n",
       " Token(byte_list=(68,)),\n",
       " Token(byte_list=(69,)),\n",
       " Token(byte_list=(70,)),\n",
       " Token(byte_list=(71,)),\n",
       " Token(byte_list=(72,)),\n",
       " Token(byte_list=(73,)),\n",
       " Token(byte_list=(74,)),\n",
       " Token(byte_list=(75,)),\n",
       " Token(byte_list=(76,)),\n",
       " Token(byte_list=(77,)),\n",
       " Token(byte_list=(78,)),\n",
       " Token(byte_list=(79,)),\n",
       " Token(byte_list=(80,)),\n",
       " Token(byte_list=(81,)),\n",
       " Token(byte_list=(82,)),\n",
       " Token(byte_list=(83,)),\n",
       " Token(byte_list=(84,)),\n",
       " Token(byte_list=(85,)),\n",
       " Token(byte_list=(86,)),\n",
       " Token(byte_list=(87,)),\n",
       " Token(byte_list=(88,)),\n",
       " Token(byte_list=(89,)),\n",
       " Token(byte_list=(90,)),\n",
       " Token(byte_list=(91,)),\n",
       " Token(byte_list=(92,)),\n",
       " Token(byte_list=(93,)),\n",
       " Token(byte_list=(94,)),\n",
       " Token(byte_list=(95,)),\n",
       " Token(byte_list=(96,)),\n",
       " Token(byte_list=(97,)),\n",
       " Token(byte_list=(98,)),\n",
       " Token(byte_list=(99,)),\n",
       " Token(byte_list=(100,)),\n",
       " Token(byte_list=(101,)),\n",
       " Token(byte_list=(102,)),\n",
       " Token(byte_list=(103,)),\n",
       " Token(byte_list=(104,)),\n",
       " Token(byte_list=(105,)),\n",
       " Token(byte_list=(106,)),\n",
       " Token(byte_list=(107,)),\n",
       " Token(byte_list=(108,)),\n",
       " Token(byte_list=(109,)),\n",
       " Token(byte_list=(110,)),\n",
       " Token(byte_list=(111,)),\n",
       " Token(byte_list=(112,)),\n",
       " Token(byte_list=(113,)),\n",
       " Token(byte_list=(114,)),\n",
       " Token(byte_list=(115,)),\n",
       " Token(byte_list=(116,)),\n",
       " Token(byte_list=(117,)),\n",
       " Token(byte_list=(118,)),\n",
       " Token(byte_list=(119,)),\n",
       " Token(byte_list=(120,)),\n",
       " Token(byte_list=(121,)),\n",
       " Token(byte_list=(122,)),\n",
       " Token(byte_list=(123,)),\n",
       " Token(byte_list=(124,)),\n",
       " Token(byte_list=(125,)),\n",
       " Token(byte_list=(126,)),\n",
       " Token(byte_list=(127,)),\n",
       " Token(byte_list=(128,)),\n",
       " Token(byte_list=(129,)),\n",
       " Token(byte_list=(130,)),\n",
       " Token(byte_list=(131,)),\n",
       " Token(byte_list=(132,)),\n",
       " Token(byte_list=(133,)),\n",
       " Token(byte_list=(134,)),\n",
       " Token(byte_list=(135,)),\n",
       " Token(byte_list=(136,)),\n",
       " Token(byte_list=(137,)),\n",
       " Token(byte_list=(138,)),\n",
       " Token(byte_list=(139,)),\n",
       " Token(byte_list=(140,)),\n",
       " Token(byte_list=(141,)),\n",
       " Token(byte_list=(142,)),\n",
       " Token(byte_list=(143,)),\n",
       " Token(byte_list=(144,)),\n",
       " Token(byte_list=(145,)),\n",
       " Token(byte_list=(146,)),\n",
       " Token(byte_list=(147,)),\n",
       " Token(byte_list=(148,)),\n",
       " Token(byte_list=(149,)),\n",
       " Token(byte_list=(150,)),\n",
       " Token(byte_list=(151,)),\n",
       " Token(byte_list=(152,)),\n",
       " Token(byte_list=(153,)),\n",
       " Token(byte_list=(154,)),\n",
       " Token(byte_list=(155,)),\n",
       " Token(byte_list=(156,)),\n",
       " Token(byte_list=(157,)),\n",
       " Token(byte_list=(158,)),\n",
       " Token(byte_list=(159,)),\n",
       " Token(byte_list=(160,)),\n",
       " Token(byte_list=(161,)),\n",
       " Token(byte_list=(162,)),\n",
       " Token(byte_list=(163,)),\n",
       " Token(byte_list=(164,)),\n",
       " Token(byte_list=(165,)),\n",
       " Token(byte_list=(166,)),\n",
       " Token(byte_list=(167,)),\n",
       " Token(byte_list=(168,)),\n",
       " Token(byte_list=(169,)),\n",
       " Token(byte_list=(170,)),\n",
       " Token(byte_list=(171,)),\n",
       " Token(byte_list=(172,)),\n",
       " Token(byte_list=(173,)),\n",
       " Token(byte_list=(174,)),\n",
       " Token(byte_list=(175,)),\n",
       " Token(byte_list=(176,)),\n",
       " Token(byte_list=(177,)),\n",
       " Token(byte_list=(178,)),\n",
       " Token(byte_list=(179,)),\n",
       " Token(byte_list=(180,)),\n",
       " Token(byte_list=(181,)),\n",
       " Token(byte_list=(182,)),\n",
       " Token(byte_list=(183,)),\n",
       " Token(byte_list=(184,)),\n",
       " Token(byte_list=(185,)),\n",
       " Token(byte_list=(186,)),\n",
       " Token(byte_list=(187,)),\n",
       " Token(byte_list=(188,)),\n",
       " Token(byte_list=(189,)),\n",
       " Token(byte_list=(190,)),\n",
       " Token(byte_list=(191,)),\n",
       " Token(byte_list=(192,)),\n",
       " Token(byte_list=(193,)),\n",
       " Token(byte_list=(194,)),\n",
       " Token(byte_list=(195,)),\n",
       " Token(byte_list=(196,)),\n",
       " Token(byte_list=(197,)),\n",
       " Token(byte_list=(198,)),\n",
       " Token(byte_list=(199,)),\n",
       " Token(byte_list=(200,)),\n",
       " Token(byte_list=(201,)),\n",
       " Token(byte_list=(202,)),\n",
       " Token(byte_list=(203,)),\n",
       " Token(byte_list=(204,)),\n",
       " Token(byte_list=(205,)),\n",
       " Token(byte_list=(206,)),\n",
       " Token(byte_list=(207,)),\n",
       " Token(byte_list=(208,)),\n",
       " Token(byte_list=(209,)),\n",
       " Token(byte_list=(210,)),\n",
       " Token(byte_list=(211,)),\n",
       " Token(byte_list=(212,)),\n",
       " Token(byte_list=(213,)),\n",
       " Token(byte_list=(214,)),\n",
       " Token(byte_list=(215,)),\n",
       " Token(byte_list=(216,)),\n",
       " Token(byte_list=(217,)),\n",
       " Token(byte_list=(218,)),\n",
       " Token(byte_list=(219,)),\n",
       " Token(byte_list=(220,)),\n",
       " Token(byte_list=(221,)),\n",
       " Token(byte_list=(222,)),\n",
       " Token(byte_list=(223,)),\n",
       " Token(byte_list=(224,)),\n",
       " Token(byte_list=(225,)),\n",
       " Token(byte_list=(226,)),\n",
       " Token(byte_list=(227,)),\n",
       " Token(byte_list=(228,)),\n",
       " Token(byte_list=(229,)),\n",
       " Token(byte_list=(230,)),\n",
       " Token(byte_list=(231,)),\n",
       " Token(byte_list=(232,)),\n",
       " Token(byte_list=(233,)),\n",
       " Token(byte_list=(234,)),\n",
       " Token(byte_list=(235,)),\n",
       " Token(byte_list=(236,)),\n",
       " Token(byte_list=(237,)),\n",
       " Token(byte_list=(238,)),\n",
       " Token(byte_list=(239,)),\n",
       " Token(byte_list=(240,)),\n",
       " Token(byte_list=(241,)),\n",
       " Token(byte_list=(242,)),\n",
       " Token(byte_list=(243,)),\n",
       " Token(byte_list=(244,)),\n",
       " Token(byte_list=(245,)),\n",
       " Token(byte_list=(246,)),\n",
       " Token(byte_list=(247,)),\n",
       " Token(byte_list=(248,)),\n",
       " Token(byte_list=(249,)),\n",
       " Token(byte_list=(250,)),\n",
       " Token(byte_list=(251,)),\n",
       " Token(byte_list=(252,)),\n",
       " Token(byte_list=(253,)),\n",
       " Token(byte_list=(254,)),\n",
       " Token(byte_list=(255,))]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [Token((b,)) for b in range(256)]\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b489c7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token(byte_list=b'\\xff\\x01\\x03')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Token with multiple stuff\n",
    "\n",
    "Token(b'\\xff\\x01\\x03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849d4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'es', 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all merges\n",
    "\n",
    "def find_next_merge(frequency_table: dict[tuple[bytes], int]):\n",
    "    pair_count = d\n",
    "\n",
    "    current_max_value = None\n",
    "    current_max_count = None\n",
    "    for word in frequency_table:\n",
    "        for i in range(len(word)-1):\n",
    "            pair = word[i:i+2]\n",
    "            count = pair_count[pair] + 1\n",
    "            pair_count[pair] = count\n",
    "\n",
    "            if current_max_count is None:\n",
    "                current_max_value = pair\n",
    "                current_max_count = pair_count[pair]\n",
    "            elif count > current_max_count or (current_max_count == count and pair < current_max_value):\n",
    "                current_max_value = pair\n",
    "                current_max_count = count\n",
    "\n",
    "current_max_value, current_max_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcdb3829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'\\x1A\\x30'[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
